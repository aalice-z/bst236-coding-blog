{
  "last_updated": "2026-02-20T01:00:22.808815",
  "count": 20,
  "papers": [
    {
      "id": "2602.16696v1",
      "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks",
      "authors": [
        "Huan Souza",
        "Pankaj Mehta"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T18:42:29Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16696v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16696v1"
    },
    {
      "id": "2602.16548v1",
      "title": "RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion",
      "authors": [
        "Tianmeng Hu",
        "Yongzheng Cui",
        "Biao Luo",
        "Ke Li"
      ],
      "abstract": "The inverse design of RNA three-dimensional (3D) structures is crucial for engineering functional RNAs in synthetic biology and therapeutics. While recent deep learning approaches have advanced this field, they are typically optimized and evaluated using native sequence recovery, which is a limited surrogate for structural fidelity, since different sequences can fold into similar 3D structures and high recovery does not necessarily indicate correct folding. To address this limitation, we propose RIDER, an RNA Inverse DEsign framework with Reinforcement learning that directly optimizes for 3D structural similarity. First, we develop and pre-train a GNN-based generative diffusion model conditioned on the target 3D structure, achieving a 9% improvement in native sequence recovery over state-of-the-art methods. Then, we fine-tune the model with an improved policy gradient algorithm using four task-specific reward functions based on 3D self-consistency metrics. Experimental results show that RIDER improves structural similarity by over 100% across all metrics and discovers designs that are distinct from native sequences.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T15:52:26Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16548v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16548v1"
    },
    {
      "id": "2602.16507v1",
      "title": "Small molecule retrieval from tandem mass spectrometry: what are we optimizing for?",
      "authors": [
        "Gaetan De Waele",
        "Marek Wydmuch",
        "Krzysztof Dembczyński",
        "Wojciech Kotłowski",
        "Willem Waegeman"
      ],
      "abstract": "One of the central challenges in the computational analysis of liquid chromatography-tandem mass spectrometry (LC-MS/MS) data is to identify the compounds underlying the output spectra. In recent years, this problem is increasingly tackled using deep learning methods. A common strategy involves predicting a molecular fingerprint vector from an input mass spectrum, which is then used to search for matches in a chemical compound database. While various loss functions are employed in training these predictive models, their impact on model performance remains poorly understood. In this study, we investigate commonly used loss functions, deriving novel regret bounds that characterize when Bayes-optimal decisions for these objectives must diverge. Our results reveal a fundamental trade-off between the two objectives of (1) fingerprint similarity and (2) molecular retrieval. Optimizing for more accurate fingerprint predictions typically worsens retrieval results, and vice versa. Our theoretical analysis shows this trade-off depends on the similarity structure of candidate sets, providing guidance for loss function and fingerprint selection.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T14:48:08Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16507v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16507v1"
    },
    {
      "id": "2602.16468v1",
      "title": "HPMixer: Hierarchical Patching for Multivariate Time Series Forecasting",
      "authors": [
        "Jung Min Choi",
        "Vijaya Krishna Yalavarthi",
        "Lars Schmidt-Thieme"
      ],
      "abstract": "In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential. To address this within standard deep learning benchmark settings, we propose the Hierarchical Patching Mixer (HPMixer), which models periodicity and residuals in a decoupled yet complementary manner. The periodic component utilizes a learnable cycle module [7] enhanced with a nonlinear channel-wise MLP for greater expressiveness. The residual component is processed through a Learnable Stationary Wavelet Transform (LSWT) to extract stable, shift-invariant frequency-domain representations. Subsequently, a channel-mixing encoder models explicit inter-channel dependencies, while a two-level non-overlapping hierarchical patching mechanism captures coarse- and fine-scale residual variations. By integrating decoupled periodicity modeling with structured, multi-scale residual learning, HPMixer provides an effective framework. Extensive experiments on standard multivariate benchmarks demonstrate that HPMixer achieves competitive or state-of-the-art performance compared to recent baselines.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T13:59:04Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16468v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16468v1"
    },
    {
      "id": "2602.16264v1",
      "title": "Prediction of Major Solar Flares Using Interpretable Class-dependent Reward Framework with Active Region Magnetograms and Domain Knowledge",
      "authors": [
        "Zixian Wu",
        "Xuebao Li",
        "Yanfang Zheng",
        "Rui Wang",
        "Shunhuang Zhang",
        "Jinfang Wei",
        "Yongshang Lv",
        "Liang Dong",
        "Zamri Zainal Abidin",
        "Noraisyah Mohamed Shah",
        "Hongwei Ye",
        "Pengchao Yan",
        "Xuefeng Li",
        "Xiaojia Ji",
        "Xusheng Huang",
        "Xiaotian Wang",
        "Honglei Jin"
      ],
      "abstract": "In this work, we develop, for the first time, a supervised classification framework with class-dependent rewards (CDR) to predict $\\geq$MM flares within 24 hr. We construct multiple datasets, covering knowledge-informed features and line-of sight (LOS) magnetograms. We also apply three deep learning models (CNN, CNN-BiLSTM, and Transformer) and three CDR counterparts (CDR-CNN, CDR-CNN-BiLSTM, and CDR-Transformer). First, we analyze the importance of LOS magnetic field parameters with the Transformer, then compare its performance using LOS-only, vector-only, and combined magnetic field parameters. Second, we compare flare prediction performance based on CDR models versus deep learning counterparts. Third, we perform sensitivity analysis on reward engineering for CDR models. Fourth, we use the SHAP method for model interpretability. Finally, we conduct performance comparison between our models and NASA/CCMC. The main findings are: (1)Among LOS feature combinations, R_VALUE and AREA_ACR consistently yield the best results. (2)Transformer achieves better performance with combined LOS and vector magnetic field data than with either alone. (3)Models using knowledge-informed features outperform those using magnetograms. (4)While CNN and CNN-BiLSTM outperform their CDR counterparts on magnetograms, CDR-Transformer is slightly superior to its deep learning counterpart when using knowledge-informed features. Among all models, CDR-Transformer achieves the best performance. (5)The predictive performance of the CDR models is not overly sensitive to the reward choices.(6)Through SHAP analysis, the CDR model tends to regard TOTUSJH as more important, while the Transformer tends to prioritize R_VALUE more.(7)Under identical prediction time and active region (AR) number, the CDR-Transformer shows superior predictive capabilities compared to NASA/CCMC.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T08:30:02Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16264v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16264v1"
    },
    {
      "id": "2602.16256v1",
      "title": "Color-based Emotion Representation for Speech Emotion Recognition",
      "authors": [
        "Ryotaro Nagase",
        "Ryoichi Takashima",
        "Yoichi Yamashita"
      ],
      "abstract": "Speech emotion recognition (SER) has traditionally relied on categorical or dimensional labels. However, this technique is limited in representing both the diversity and interpretability of emotions. To overcome this limitation, we focus on color attributes, such as hue, saturation, and value, to represent emotions as continuous and interpretable scores. We annotated an emotional speech corpus with color attributes via crowdsourcing and analyzed them. Moreover, we built regression models for color attributes in SER using machine learning and deep learning, and explored the multitask learning of color attribute regression and emotion classification. As a result, we demonstrated the relationship between color attributes and emotions in speech, and successfully developed color attribute regression models for SER. We also showed that multitask learning improved the performance of each task.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T08:11:49Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16256v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16256v1"
    },
    {
      "id": "2602.16224v1",
      "title": "Amortized Predictability-aware Training Framework for Time Series Forecasting and Classification",
      "authors": [
        "Xu Zhang",
        "Peng Wang",
        "Yichen Li",
        "Wei Wang"
      ],
      "abstract": "Time series data are prone to noise in various domains, and training samples may contain low-predictability patterns that deviate from the normal data distribution, leading to training instability or convergence to poor local minima. Therefore, mitigating the adverse effects of low-predictability samples is crucial for time series analysis tasks such as time series forecasting (TSF) and time series classification (TSC). While many deep learning models have achieved promising performance, few consider how to identify and penalize low-predictability samples to improve model performance from the training perspective. To fill this gap, we propose a general Amortized Predictability-aware Training Framework (APTF) for both TSF and TSC. APTF introduces two key designs that enable the model to focus on high-predictability samples while still learning appropriately from low-predictability ones: (i) a Hierarchical Predictability-aware Loss (HPL) that dynamically identifies low-predictability samples and progressively expands their loss penalty as training evolves, and (ii) an amortization model that mitigates predictability estimation errors caused by model bias, further enhancing HPL's effectiveness. The code is available at https://github.com/Meteor-Stars/APTF.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T06:59:05Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16224v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16224v1"
    },
    {
      "id": "2602.16216v1",
      "title": "UCTECG-Net: Uncertainty-aware Convolution Transformer ECG Network for Arrhythmia Detection",
      "authors": [
        "Hamzeh Asgharnezhad",
        "Pegah Tabarisaadi",
        "Abbas Khosravi",
        "Roohallah Alizadehsani",
        "U. Rajendra Acharya"
      ],
      "abstract": "Deep learning has improved automated electrocardiogram (ECG) classification, but limited insight into prediction reliability hinders its use in safety-critical settings. This paper proposes UCTECG-Net, an uncertainty-aware hybrid architecture that combines one-dimensional convolutions and Transformer encoders to process raw ECG signals and their spectrograms jointly. Evaluated on the MIT-BIH Arrhythmia and PTB Diagnostic datasets, UCTECG-Net outperforms LSTM, CNN1D, and Transformer baselines in terms of accuracy, precision, recall and F1 score, achieving up to 98.58% accuracy on MIT-BIH and 99.14% on PTB. To assess predictive reliability, we integrate three uncertainty quantification methods (Monte Carlo Dropout, Deep Ensembles, and Ensemble Monte Carlo Dropout) into all models and analyze their behavior using an uncertainty-aware confusion matrix and derived metrics. The results show that UCTECG-Net, particularly with Ensemble or EMCD, provides more reliable and better-aligned uncertainty estimates than competing architectures, offering a stronger basis for risk-aware ECG decision support.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T06:39:19Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16216v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16216v1"
    },
    {
      "id": "2602.16204v1",
      "title": "Linked Data Classification using Neurochaos Learning",
      "authors": [
        "Pooja Honna",
        "Ayush Patravali",
        "Nithin Nagaraj",
        "Nanjangud C. Narendra"
      ],
      "abstract": "Neurochaos Learning (NL) has shown promise in recent times over traditional deep learning due to its two key features: ability to learn from small sized training samples, and low compute requirements. In prior work, NL has been implemented and extensively tested on separable and time series data, and demonstrated its superior performance on both classification and regression tasks. In this paper, we investigate the next step in NL, viz., applying NL to linked data, in particular, data that is represented in the form of knowledge graphs. We integrate linked data into NL by implementing node aggregation on knowledge graphs, and then feeding the aggregated node features to the simplest NL architecture: ChaosNet. We demonstrate the results of our implementation on homophilic graph datasets as well as heterophilic graph datasets of verying heterophily. We show better efficacy of our approach on homophilic graphs than on heterophilic graphs. While doing so, we also present our analysis of the results, as well as suggestions for future work.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T05:55:59Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16204v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16204v1"
    },
    {
      "id": "2602.16101v1",
      "title": "Axle Sensor Fusion for Online Continual Wheel Fault Detection in Wayside Railway Monitoring",
      "authors": [
        "Afonso Lourenço",
        "Francisca Osório",
        "Diogo Risca",
        "Goreti Marreiros"
      ],
      "abstract": "Reliable and cost-effective maintenance is essential for railway safety, particularly at the wheel-rail interface, which is prone to wear and failure. Predictive maintenance frameworks increasingly leverage sensor-generated time-series data, yet traditional methods require manual feature engineering, and deep learning models often degrade in online settings with evolving operational patterns. This work presents a semantic-aware, label-efficient continual learning framework for railway fault diagnostics. Accelerometer signals are encoded via a Variational AutoEncoder into latent representations capturing the normal operational structure in a fully unsupervised manner. Importantly, semantic metadata, including axle counts, wheel indexes, and strain-based deformations, is extracted via AI-driven peak detection on fiber Bragg grating sensors (resistant to electromagnetic interference) and fused with the VAE embeddings, enhancing anomaly detection under unknown operational conditions. A lightweight gradient boosting supervised classifier stabilizes anomaly scoring with minimal labels, while a replay-based continual learning strategy enables adaptation to evolving domains without catastrophic forgetting. Experiments show the model detects minor imperfections due to flats and polygonization, while adapting to evolving operational conditions, such as changes in train type, speed, load, and track profiles, captured using a single accelerometer and strain gauge in wayside monitoring.",
      "published": "February 18, 2026",
      "published_raw": "2026-02-18T00:14:18Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16101v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16101v1"
    },
    {
      "id": "2602.16000v1",
      "title": "Imaging-Derived Coronary Fractional Flow Reserve: Advances in Physics-Based, Machine-Learning, and Physics-Informed Methods",
      "authors": [
        "Tanxin Zhu",
        "Emran Hossen",
        "Chen Zhao",
        "Michele Esposito",
        "Jiguang Sun",
        "Weihua Zhou"
      ],
      "abstract": "Purpose of Review Imaging derived fractional flow reserve (FFR) is rapidly evolving beyond conventional computational fluid dynamics (CFD) based pipelines toward machine learning (ML), deep learning (DL), and physics informed approaches that enable fast, wire free, and scalable functional assessment of coronary stenosis. This review synthesizes recent advances in CT and angiography based FFR, with particular emphasis on emerging physics informed neural networks and neural operators (PINNs and PINOs) and key considerations for their clinical translation. Recent Findings ML/DL approaches have markedly improved automation and computational speed, enabling prediction of pressure and FFR from anatomical descriptors or angiographic contrast dynamics. However, their real-world performance and generalizability can remain variable and sensitive to domain shift, due to multi-center heterogeneity, interpretability challenges, and differences in acquisition protocols and image quality. Physics informed learning introduces conservation structure and boundary condition consistency into model training, improving generalizability and reducing dependence on dense supervision while maintaining rapid inference. Recent evaluation trends increasingly highlight deployment oriented metrics, including calibration, uncertainty quantification, and quality control gatekeeping, as essential for safe clinical use. Summary The field is converging toward imaging derived FFR methods that are faster, more automated, and more reliable. While ML/DL offers substantial efficiency gains, physics informed frameworks such as PINNs and PINOs may provide a more robust balance between speed and physical consistency. Prospective multi center validation and standardized evaluation will be critical to support broad and safe clinical adoption.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T20:46:25Z",
      "pdf_link": "http://arxiv.org/pdf/2602.16000v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.16000v1"
    },
    {
      "id": "2602.15961v1",
      "title": "R$^2$Energy: A Large-Scale Benchmark for Robust Renewable Energy Forecasting under Diverse and Extreme Conditions",
      "authors": [
        "Zhi Sheng",
        "Yuan Yuan",
        "Guozhen Zhang",
        "Yong Li"
      ],
      "abstract": "The rapid expansion of renewable energy, particularly wind and solar power, has made reliable forecasting critical for power system operations. While recent deep learning models have achieved strong average accuracy, the increasing frequency and intensity of climate-driven extreme weather events pose severe threats to grid stability and operational security. Consequently, developing robust forecasting models that can withstand volatile conditions has become a paramount challenge. In this paper, we present R$^2$Energy, a large-scale benchmark for NWP-assisted renewable energy forecasting. It comprises over 10.7 million high-fidelity hourly records from 902 wind and solar stations across four provinces in China, providing the diverse meteorological conditions necessary to capture the wide-ranging variability of renewable generation. We further establish a standardized, leakage-free forecasting paradigm that grants all models identical access to future Numerical Weather Prediction (NWP) signals, enabling fair and reproducible comparison across state-of-the-art representative forecasting architectures. Beyond aggregate accuracy, we incorporate regime-wise evaluation with expert-aligned extreme weather annotations, uncovering a critical ``robustness gap'' typically obscured by average metrics. This gap reveals a stark robustness-complexity trade-off: under extreme conditions, a model's reliability is driven by its meteorological integration strategy rather than its architectural complexity. R$^2$Energy provides a principled foundation for evaluating and developing forecasting models for safety-critical power system applications.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T19:22:49Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15961v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15961v1"
    },
    {
      "id": "2602.15930v1",
      "title": "A targeted machine learning approach for detecting diffuse radio emission with Astronomaly: Protege",
      "authors": [
        "Verlon Etsebeth",
        "Michelle Lochner",
        "Konstantinos Kolokythas",
        "Kenda Knowles",
        "Emma Tolley"
      ],
      "abstract": "Diffuse radio emission in galaxy clusters, such as radio halos, relics, and mini halos, is a key tracer of non-thermal processes, turbulence, and magnetic fields within the intra-cluster medium. However, their low surface brightness, as well as contamination from compact sources and imaging artefacts, makes their detection challenging. The sheer volume of data from instruments such as the Square Kilometre Array will render traditional manual-inspection based detection methods infeasible. This paper introduces a novel machine learning approach that uses active learning to rapidly identify diffuse emission candidates from a small, optimally-selected subset of data. We apply the self-supervised deep learning algorithm Bootstrap Your Own Latent to extract features from source cutouts in the MeerKAT Galaxy Cluster Legacy Survey (MGCLS). We then pass these features through the Astronomaly: Protege anomaly detection framework to identify the final candidates. Using a human-labelled set, we evaluate our pipeline on high-resolution (~7''), convolved (15''), and combined-feature MGCLS datasets. Interestingly, the high-resolution features identify diffuse sources more efficiently than the convolved resolution, which are in turn outperformed by the combined features. Of the top 100 sources ranked by Protege, 99% exhibit diffuse characteristics, with 55% confirmed as cluster-related emission. Our work shows that Protege can identify diffuse emission with minimal human labelling effort, offering a powerful, scalable tool capable of detecting both known and novel diffuse radio sources.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T19:00:01Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15930v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15930v1"
    },
    {
      "id": "2602.15830v1",
      "title": "Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution",
      "authors": [
        "Christopher David Roberts"
      ],
      "abstract": "Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train data-driven ensemble forecasts or post-processing methods when large training ensembles are either unavailable or computationally prohibitive. The adjusted continuous ranked probability score (aCRPS) is fair and unbiased with respect to ensemble size, provided forecast members are exchangeable and interpretable as conditionally independent draws from an underlying predictive distribution. However, distribution-aware post-processing methods that introduce structural dependency between members can violate this assumption, rendering aCRPS unfair. We demonstrate this effect using two approaches designed to minimize the expected aCRPS of a finite ensemble: (1) a linear member-by-member calibration, which couples members through a common dependency on the sample ensemble mean, and (2) a deep-learning method, which couples members via transformer self-attention across the ensemble dimension. In both cases, the results are sensitive to ensemble size and apparent gains in aCRPS can correspond to systematic unreliability characterized by over-dispersion. We introduce trajectory transformers as a proof-of-concept that ensemble-size independence can be achieved. This approach is an adaptation of the Post-processing Ensembles with Transformers (PoET) framework and applies self-attention over lead time while preserving the conditional independence required by aCRPS. When applied to weekly mean $T_{2m}$ forecasts from the ECMWF subseasonal forecasting system, this approach successfully reduces systematic model biases whilst also improving or maintaining forecast reliability regardless of the ensemble size used in training (3 vs 9 members) or real-time forecasts (9 vs 100 members).",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T18:59:55Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15830v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15830v1"
    },
    {
      "id": "2602.15926v1",
      "title": "A Study on Real-time Object Detection using Deep Learning",
      "authors": [
        "Ankita Bose",
        "Jayasravani Bhumireddy",
        "Naveen N"
      ],
      "abstract": "Object detection has compelling applications over a range of domains, including human-computer interfaces, security and video surveillance, navigation and road traffic monitoring, transportation systems, industrial automation healthcare, the world of Augmented Reality (AR) and Virtual Reality (VR), environment monitoring and activity identification. Applications of real time object detection in all these areas provide dynamic analysis of the visual information that helps in immediate decision making. Furthermore, advanced deep learning algorithms leverage the progress in the field of object detection providing more accurate and efficient solutions. There are some outstanding deep learning algorithms for object detection which includes, Faster R CNN(Region-based Convolutional Neural Network),Mask R-CNN, Cascade R-CNN, YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), RetinaNet etc. This article goes into great detail on how deep learning algorithms are used to enhance real time object recognition. It provides information on the different object detection models available, open benchmark datasets, and studies on the use of object detection models in a range of applications. Additionally, controlled studies are provided to compare various strategies and produce some illuminating findings. Last but not least, a number of encouraging challenges and approaches are offered as suggestions for further investigation in both relevant deep learning approaches and object recognition.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T18:12:42Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15926v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15926v1"
    },
    {
      "id": "2602.15923v1",
      "title": "A fully differentiable framework for training proxy Exchange Correlation Functionals for periodic systems",
      "authors": [
        "Rakshit Kumar Singh",
        "Aryan Amit Barsainyan",
        "Bharath Ramsundar"
      ],
      "abstract": "Density Functional Theory (DFT) is widely used for first-principles simulations in chemistry and materials science, but its computational cost remains a key limitation for large systems. Motivated by recent advances in ML-based exchange-correlation (XC) functionals, this paper introduces a differentiable framework that integrates machine learning models into density functional theory (DFT) for solids and other periodic systems. The framework defines a clean API for neural network models that can act as drop in replacements for conventional exchange-correlation (XC) functionals and enables gradients to flow through the full self-consistent DFT workflow. The framework is implemented in Python using a PyTorch backend, making it fully differentiable and easy to use with standard deep learning tools. We integrate the implementation with the DeepChem library to promote the reuse of established models and to lower the barrier for experimentation. In initial benchmarks against established electronic structure packages (GPAW and PySCF), our models achieve relative errors on the order of 5-10%.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T16:13:07Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15923v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15923v1"
    },
    {
      "id": "2602.15637v1",
      "title": "The Stationarity Bias: Stratified Stress-Testing for Time-Series Imputation in Regulated Dynamical Systems",
      "authors": [
        "Amirreza Dolatpour Fathkouhi",
        "Alireza Namazi",
        "Heman Shakeri"
      ],
      "abstract": "Time-series imputation benchmarks employ uniform random masking and shape-agnostic metrics (MSE, RMSE), implicitly weighting evaluation by regime prevalence. In systems with a dominant attractor -- homeostatic physiology, nominal industrial operation, stable network traffic -- this creates a systematic \\emph{Stationarity Bias}: simple methods appear superior because the benchmark predominantly samples the easy, low-entropy regime where they trivially succeed. We formalize this bias and propose a \\emph{Stratified Stress-Test} that partitions evaluation into Stationary and Transient regimes. Using Continuous Glucose Monitoring (CGM) as a testbed -- chosen for its rigorous ground-truth forcing functions (meals, insulin) that enable precise regime identification -- we establish three findings with broad implications:(i)~Stationary Efficiency: Linear interpolation achieves state-of-the-art reconstruction during stable intervals, confirming that complex architectures are computationally wasteful in low-entropy regimes.(ii)~Transient Fidelity: During critical transients (post-prandial peaks, hypoglycemic events), linear methods exhibit drastically degraded morphological fidelity (DTW), disproportionate to their RMSE -- a phenomenon we term the \\emph{RMSE Mirage}, where low pointwise error masks the destruction of signal shape.(iii)~Regime-Conditional Model Selection: Deep learning models preserve both pointwise accuracy and morphological integrity during transients, making them essential for safety-critical downstream tasks. We further derive empirical missingness distributions from clinical trials and impose them on complete training data, preventing models from exploiting unrealistically clean observations and encouraging robustness under real-world missingness. This framework generalizes to any regulated system where routine stationarity dominates critical transients.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T15:05:56Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15637v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15637v1"
    },
    {
      "id": "2602.15602v1",
      "title": "Certified Per-Instance Unlearning Using Individual Sensitivity Bounds",
      "authors": [
        "Hanna Benarroch",
        "Jamal Atif",
        "Olivier Cappé"
      ],
      "abstract": "Certified machine unlearning can be achieved via noise injection leading to differential privacy guarantees, where noise is calibrated to worst-case sensitivity. Such conservative calibration often results in performance degradation, limiting practical applicability. In this work, we investigate an alternative approach based on adaptive per-instance noise calibration tailored to the individual contribution of each data point to the learned solution. This raises the following challenge: how can one establish formal unlearning guarantees when the mechanism depends on the specific point to be removed? To define individual data point sensitivities in noisy gradient dynamics, we consider the use of per-instance differential privacy. For ridge regression trained via Langevin dynamics, we derive high-probability per-instance sensitivity bounds, yielding certified unlearning with substantially less noise injection. We corroborate our theoretical findings through experiments in linear settings and provide further empirical evidence on the relevance of the approach in deep learning settings.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T14:18:47Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15602v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15602v1"
    },
    {
      "id": "2602.15552v1",
      "title": "Latent Regularization in Generative Test Input Generation",
      "authors": [
        "Giorgi Merabishvili",
        "Oliver Weißl",
        "Andrea Stocco"
      ],
      "abstract": "This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T12:57:17Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15552v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15552v1"
    },
    {
      "id": "2602.15484v1",
      "title": "Bottleneck Transformer-Based Approach for Improved Automatic STOI Score Prediction",
      "authors": [
        " Amartyaveer",
        "Murali Kadambi",
        "Chandra Mohan Sharma",
        "Anupam Mondal",
        "Prasanta Kumar Ghosh"
      ],
      "abstract": "In this study, we have presented a novel approach to predict the Short-Time Objective Intelligibility (STOI) metric using a bottleneck transformer architecture. Traditional methods for calculating STOI typically requires clean reference speech, which limits their applicability in the real world. To address this, numerous deep learning-based nonintrusive speech assessment models have garnered significant interest. Many studies have achieved commendable performance, but there is room for further improvement. We propose the use of bottleneck transformer, incorporating convolution blocks for learning frame-level features and a multi-head self-attention (MHSA) layer to aggregate the information. These components enable the transformer to focus on the key aspects of the input data. Our model has shown higher correlation and lower mean squared error for both seen and unseen scenarios compared to the state-of-the-art model using self-supervised learning (SSL) and spectral features as inputs.",
      "published": "February 17, 2026",
      "published_raw": "2026-02-17T10:46:54Z",
      "pdf_link": "http://arxiv.org/pdf/2602.15484v1.pdf",
      "arxiv_link": "http://arxiv.org/abs/2602.15484v1"
    }
  ]
}